import streamlit as st
import pandas as pd
import yfinance as yf
import requests
from bs4 import BeautifulSoup
import math
import time
import os
import itertools
import json
import re
from datetime import datetime, time as dt_time, timedelta
import pytz
from decimal import Decimal, ROUND_HALF_UP
import io
import twstock  # å¿…é ˆå®‰è£: pip install twstock

# ==========================================
# 0. é é¢è¨­å®šèˆ‡åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="ç•¶æ²–æˆ°ç•¥å®¤", page_icon="âš¡", layout="wide")
st.title("âš¡ ç•¶æ²–æˆ°ç•¥å®¤ âš¡")

CONFIG_FILE = "config.json"
DATA_CACHE_FILE = "data_cache.json"
URL_CACHE_FILE = "url_cache.json"
SEARCH_CACHE_FILE = "search_cache.json"

def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f: return json.load(f)
        except: return {}
    return {}

def save_config(font_size, limit_rows):
    try:
        config = {
            "font_size": font_size,
            "limit_rows": limit_rows
        }
        with open(CONFIG_FILE, "w") as f: json.dump(config, f)
        return True
    except: return False

def save_data_cache(df, ignored_set, candidates=[]):
    try:
        df_save = df.fillna("")
        data_to_save = {
            "stock_data": df_save.to_dict(orient='records'),
            "ignored_stocks": list(ignored_set),
            "all_candidates": candidates
        }
        with open(DATA_CACHE_FILE, "w", encoding='utf-8') as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=4)
    except: pass

def load_data_cache():
    if os.path.exists(DATA_CACHE_FILE):
        try:
            with open(DATA_CACHE_FILE, "r", encoding='utf-8') as f:
                data = json.load(f)
            df = pd.DataFrame(data.get('stock_data', []))
            ignored = set(data.get('ignored_stocks', []))
            candidates = data.get('all_candidates', [])
            return df, ignored, candidates
        except: return pd.DataFrame(), set(), []
    return pd.DataFrame(), set(), []

def load_url_history():
    if os.path.exists(URL_CACHE_FILE):
        try:
            with open(URL_CACHE_FILE, "r", encoding='utf-8') as f:
                data = json.load(f)
                if "url" in data and isinstance(data["url"], str) and data["url"]:
                    return [data["url"]]
                return data.get("urls", [])
        except: return []
    return []

def save_url_history(urls):
    try:
        unique_urls = []
        seen = set()
        for u in urls:
            u_clean = u.strip()
            if u_clean and u_clean not in seen:
                unique_urls.append(u_clean)
                seen.add(u_clean)
       
        with open(URL_CACHE_FILE, "w", encoding='utf-8') as f:
            json.dump({"urls": unique_urls}, f)
        return True
    except: return False

def load_search_cache():
    if os.path.exists(SEARCH_CACHE_FILE):
        try:
            with open(SEARCH_CACHE_FILE, "r", encoding='utf-8') as f:
                data = json.load(f)
            return data.get("selected", [])
        except: return []
    return []

def save_search_cache(selected_items):
    try:
        with open(SEARCH_CACHE_FILE, "w", encoding='utf-8') as f:
            json.dump({"selected": selected_items}, f, ensure_ascii=False)
    except: pass

# --- åˆå§‹åŒ– Session State ---
if 'stock_data' not in st.session_state:
    cached_df, cached_ignored, cached_candidates = load_data_cache()
    st.session_state.stock_data = cached_df
    st.session_state.ignored_stocks = cached_ignored
    st.session_state.all_candidates = cached_candidates

if 'ignored_stocks' not in st.session_state:
    st.session_state.ignored_stocks = set()
if 'all_candidates' not in st.session_state:
    st.session_state.all_candidates = []
if 'calc_base_price' not in st.session_state:
    st.session_state.calc_base_price = 100.0
if 'calc_view_price' not in st.session_state:
    st.session_state.calc_view_price = 100.0
if 'url_history' not in st.session_state:
    st.session_state.url_history = load_url_history()
if 'cloud_url_input' not in st.session_state:
    st.session_state.cloud_url_input = st.session_state.url_history[0] if st.session_state.url_history else ""
if 'search_multiselect' not in st.session_state:
    st.session_state.search_multiselect = load_search_cache()
if 'saved_notes' not in st.session_state:
    st.session_state.saved_notes = {}
if 'futures_list' not in st.session_state:
    st.session_state.futures_list = set()

saved_config = load_config()
if 'font_size' not in st.session_state:
    st.session_state.font_size = saved_config.get('font_size', 15)
if 'limit_rows' not in st.session_state:
    st.session_state.limit_rows = saved_config.get('limit_rows', 5)

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
   
    current_font_size = st.slider(
        "å­—é«”å¤§å° (è¡¨æ ¼)",
        min_value=12,
        max_value=72,
        value=st.session_state.font_size,
        key='font_size_slider'
    )
    st.session_state.font_size = current_font_size
   
    hide_non_stock = st.checkbox("éš±è—éå€‹è‚¡ (ETF/æ¬Šè­‰/å‚µåˆ¸)", value=True)
   
    st.markdown("---")
   
    current_limit_rows = st.number_input(
        "é¡¯ç¤ºç­†æ•¸ (æª”æ¡ˆ/é›²ç«¯)",
        min_value=1,
        value=st.session_state.limit_rows,
        key='limit_rows_input',
        help="æ­¤è¨­å®šé™åˆ¶ã€Œæª”æ¡ˆ/é›²ç«¯ã€ä¾†æºçš„è‚¡ç¥¨æ•¸é‡ã€‚å¿«é€ŸæŸ¥è©¢çš„è‚¡ç¥¨æœƒé¡å¤–é¡¯ç¤ºã€‚"
    )
    st.session_state.limit_rows = current_limit_rows
   
    if st.button("ğŸ’¾ å„²å­˜è¨­å®š"):
        if save_config(current_font_size, current_limit_rows):
            st.toast("è¨­å®šå·²å„²å­˜ï¼", icon="âœ…")
           
    st.markdown("### è³‡æ–™ç®¡ç†")
    st.write(f"ğŸš« å·²å¿½ç•¥ **{len(st.session_state.ignored_stocks)}** æª”")
   
    col_restore, col_clear = st.columns([1, 1])
    with col_restore:
        if st.button("â™»ï¸ å¾©åŸ", use_container_width=True):
            st.session_state.ignored_stocks.clear()
            save_data_cache(st.session_state.stock_data, st.session_state.ignored_stocks, st.session_state.all_candidates)
            st.toast("å·²é‡ç½®å¿½ç•¥åå–®ã€‚", icon="ğŸ”„")
            st.rerun()
    with col_clear:
        if st.button("ğŸ—‘ï¸ æ¸…ç©º", type="primary", use_container_width=True, help="æ¸…ç©ºæ‰€æœ‰åˆ†æè³‡æ–™ (ä¸æœƒåˆªé™¤è¨˜æ†¶çš„ç¶²å€)"):
            st.session_state.stock_data = pd.DataFrame()
            st.session_state.ignored_stocks = set()
            st.session_state.all_candidates = []
            st.session_state.search_multiselect = []
            st.session_state.saved_notes = {}
            save_search_cache([])
            if os.path.exists(DATA_CACHE_FILE):
                os.remove(DATA_CACHE_FILE)
            st.toast("è³‡æ–™å·²å…¨éƒ¨æ¸…ç©º", icon="ğŸ—‘ï¸")
            st.rerun()
   
    if st.button("ğŸ§¹ æ¸…é™¤æ‰‹å‹•å‚™è¨»", use_container_width=True, help="æ¸…é™¤æ‰€æœ‰è¨˜æ†¶çš„æˆ°ç•¥å‚™è¨»å…§å®¹"):
        st.session_state.saved_notes = {}
        st.toast("æ‰‹å‹•å‚™è¨»å·²æ¸…é™¤", icon="ğŸ§¹")
        if not st.session_state.stock_data.empty:
             for idx in st.session_state.stock_data.index:
                 if '_auto_note' in st.session_state.stock_data.columns:
                     st.session_state.stock_data.at[idx, 'æˆ°ç•¥å‚™è¨»'] = st.session_state.stock_data.at[idx, '_auto_note']
        st.rerun()
    st.caption("åŠŸèƒ½èªªæ˜")
    st.info("ğŸ—‘ï¸ **å¦‚ä½•åˆªé™¤è‚¡ç¥¨ï¼Ÿ**\n\nåœ¨è¡¨æ ¼å·¦å´å‹¾é¸ã€Œåˆªé™¤ã€æ¡†ï¼Œè³‡æ–™å°‡æœƒç«‹å³ç§»é™¤ä¸¦**è‡ªå‹•éè£œä¸‹ä¸€æª”**ã€‚")
   
    st.markdown("---")
    st.markdown("### ğŸ”— å¤–éƒ¨è³‡æº")
    st.link_button("ğŸ“¥ Goodinfo ç•¶æ—¥é€±è½‰ç‡æ’è¡Œ", "https://reurl.cc/Or9e37", use_container_width=True, help="é»æ“Šå‰å¾€ Goodinfo ç¶²ç«™ä¸‹è¼‰ CSV")

# --- å‹•æ…‹ CSS ---
font_px = f"{st.session_state.font_size}px"
zoom_level = current_font_size / 14.0
st.markdown(f"""
    <style>
    div[data-testid="stDataFrame"] {{
        width: 100%;
        zoom: {zoom_level};
    }}
    div[data-testid="stDataFrame"] table,
    div[data-testid="stDataFrame"] thead,
    div[data-testid="stDataFrame"] tbody,
    div[data-testid="stDataFrame"] tr,
    div[data-testid="stDataFrame"] th,
    div[data-testid="stDataFrame"] td,
    div[data-testid="stDataFrame"] div,
    div[data-testid="stDataFrame"] span,
    div[data-testid="stDataFrame"] p {{
        font-family: 'Microsoft JhengHei', sans-serif !important;
    }}
    div[data-testid="stDataFrame"] input {{
        font-family: 'Microsoft JhengHei', sans-serif !important;
        font-size: 0.9rem !important;
    }}
    thead tr th:first-child {{ display:none }}
    tbody th {{ display:none }}
    .block-container {{ padding-top: 4.5rem; padding-bottom: 1rem; }}
    [data-testid="stMetricValue"] {{ font-size: 1.2em; }}
    div[data-testid="column"] {{
        padding-left: 0.1rem !important;
        padding-right: 0.1rem !important;
    }}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 1. è³‡æ–™åº«èˆ‡ç¶²è·¯åŠŸèƒ½ï¼ˆä¿æŒåŸæ¨£ï¼‰
# ==========================================
@st.cache_data
def load_local_stock_names():
    code_map = {}
    name_map = {}
    if os.path.exists("stock_names.csv"):
        try:
            df = pd.read_csv("stock_names.csv", header=None, names=["code", "name"], dtype=str)
            for _, row in df.iterrows():
                c = str(row['code']).strip()
                n = str(row['name']).strip()
                code_map[c] = n
                name_map[n] = c
        except: pass
    return code_map, name_map

@st.cache_data(ttl=86400)
def get_stock_name_online(code):
    code = str(code).strip()
    code_map, _ = load_local_stock_names()
    if code in code_map: return code_map[code]
    return code

@st.cache_data(ttl=86400)
def search_code_online(query):
    query = query.strip()
    if query.isdigit(): return query
    _, name_map = load_local_stock_names()
    if query in name_map: return name_map[query]
    return None

@st.cache_data(ttl=86400)
def fetch_futures_list():
    try:
        url = "https://www.taifex.com.tw/cht/2/stockLists"
        dfs = pd.read_html(url)
        if dfs:
            for df in dfs:
                if 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
                    return set(df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip().tolist())
                if 'Stock Code' in df.columns:
                    return set(df['Stock Code'].astype(str).str.strip().tolist())
    except:
        pass
    return set()

def get_live_price(code):
    try:
        realtime_data = twstock.realtime.get(code)
        if realtime_data and realtime_data.get('success'):
            price_str = realtime_data['realtime'].get('latest_trade_price')
            if price_str and price_str != '-' and float(price_str) > 0:
                return float(price_str)
            bids = realtime_data['realtime'].get('best_bid_price', [])
            if bids and bids[0] and bids[0] != '-':
                 return float(bids[0])
    except: pass
    try:
        ticker = yf.Ticker(f"{code}.TW")
        price = ticker.fast_info.get('last_price')
        if price and not math.isnan(price): return float(price)
        ticker = yf.Ticker(f"{code}.TWO")
        price = ticker.fast_info.get('last_price')
        if price and not math.isnan(price): return float(price)
    except: pass
    return None

def fetch_yahoo_web_backup(code):
    try:
        url = f"https://tw.stock.yahoo.com/quote/{code}"
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        r = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(r.text, 'html.parser')
       
        price_tag = soup.find('span', class_='Fz(32px)')
        if not price_tag: return None, None
        price = float(price_tag.text.replace(',', ''))
       
        change_tag = soup.find('span', class_='Fz(20px)')
        change = 0.0
        if change_tag:
             change_txt = change_tag.text.strip().replace('â–²', '').replace('â–¼', '').replace('+', '').replace(',', '')
             parent = change_tag.parent
             if 'C($c-trend-down)' in str(parent):
                 change = -float(change_txt)
             else:
                 change = float(change_txt)
                
        prev_close = price - change
       
        open_p = price
        high_p = price
        low_p = price
       
        details = soup.find_all('li', class_='price-detail-item')
        for item in details:
            label = item.find('span', class_='C(#6e7780)')
            val_tag = item.find('span', class_='Fw(600)')
            if label and val_tag:
                lbl = label.text.strip()
                val_txt = val_tag.text.strip().replace(',', '')
                if val_txt == '-': continue
                val = float(val_txt)
                if "é–‹ç›¤" in lbl: open_p = val
                elif "æœ€é«˜" in lbl: high_p = val
                elif "æœ€ä½" in lbl: low_p = val
        today = datetime.now().date()
        data = {
            'Open': [open_p], 'High': [high_p], 'Low': [low_p], 'Close': [price], 'Volume': [0]
        }
        df = pd.DataFrame(data, index=[pd.to_datetime(today)])
       
        return df, prev_close
    except:
        return None, None

def fetch_finmind_backup(code):
    try:
        start_date = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
        url = f"https://api.finmindtrade.com/api/v4/data?dataset=TaiwanStockPrice&data_id={code}&start_date={start_date}"
        r = requests.get(url, timeout=5)
        data_json = r.json()
       
        if data_json.get('msg') == 'success' and data_json.get('data'):
            df = pd.DataFrame(data_json['data'])
            df['Date'] = pd.to_datetime(df['date'])
            df = df.set_index('Date')
            rename_map = {
                'open': 'Open', 'max': 'High', 'min': 'Low', 'close': 'Close', 'Trading_Volume': 'Volume'
            }
            df = df.rename(columns=rename_map)
            cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            for c in cols:
                if c not in df.columns:
                    if c.lower() in df.columns: df[c] = df[c.lower()]
                    else: df[c] = 0.0
                df[c] = pd.to_numeric(df[c], errors='coerce')
           
            return df[cols]
    except: pass
    return None

# ==========================================
# 2. æ ¸å¿ƒè¨ˆç®—é‚è¼¯ï¼ˆä¿æŒåŸæ¨£ï¼‰
# ==========================================
def get_tick_size(price):
    try: price = float(price)
    except: return 0.01
    if pd.isna(price) or price <= 0: return 0.01
    if price < 10: return 0.01
    if price < 50: return 0.05
    if price < 100: return 0.1
    if price < 500: return 0.5
    if price < 1000: return 1.0
    return 5.0

def calculate_limits(price):
    try:
        p = float(price)
        if math.isnan(p) or p <= 0: return 0, 0
        raw_up = p * 1.10
        tick_up = get_tick_size(raw_up)
        limit_up = math.floor(raw_up / tick_up) * tick_up
        raw_down = p * 0.90
        tick_down = get_tick_size(raw_down)
        limit_down = math.ceil(raw_down / tick_down) * tick_down
        return float(f"{limit_up:.2f}"), float(f"{limit_down:.2f}")
    except: return 0, 0

def apply_tick_rules(price):
    try:
        p = float(price)
        if math.isnan(p): return 0.0
        tick = get_tick_size(p)
        rounded = (Decimal(str(p)) / Decimal(str(tick))).quantize(Decimal("1"), rounding=ROUND_HALF_UP) * Decimal(str(tick))
        return float(rounded)
    except: return price

def move_tick(price, steps):
    try:
        curr = float(price)
        if steps > 0:
            for _ in range(steps):
                tick = get_tick_size(curr)
                curr = round(curr + tick, 2)
        elif steps < 0:
            for _ in range(abs(steps)):
                tick = get_tick_size(curr - 0.0001)
                curr = round(curr - tick, 2)
        return curr
    except: return price

def apply_sr_rules(price, base_price):
    try:
        p = float(price)
        if math.isnan(p): return 0.0
        tick = get_tick_size(p)
        d_val = Decimal(str(p))
        d_tick = Decimal(str(tick))
        if p < base_price: return float(math.ceil(d_val / d_tick) * d_tick)
        elif p > base_price: return float(math.floor(d_val / d_tick) * d_tick)
        else: return apply_tick_rules(p)
    except: return price

def fmt_price(v):
    try:
        if pd.isna(v) or v == "": return ""
        return f"{float(v):.2f}".rstrip('0').rstrip('.')
    except: return str(v)

def calculate_note_width(series, font_size):
    def get_width(s):
        w = 0
        for c in str(s): w += 2.0 if ord(c) > 127 else 1.0
        return w
    if series.empty: return 50
    max_w = series.apply(get_width).max()
    if pd.isna(max_w): max_w = 0
    pixel_width = int(max_w * (font_size * 0.44))
    return max(50, pixel_width)

def recalculate_row(row, points_map):
    custom_price = row.get('è‡ªè¨‚åƒ¹(å¯ä¿®)')
    code = row.get('ä»£è™Ÿ')
    status = ""
    if pd.isna(custom_price) or str(custom_price).strip() == "": return status
   
    try:
        price = float(custom_price)
        limit_up = row.get('ç•¶æ—¥æ¼²åœåƒ¹')
        limit_down = row.get('ç•¶æ—¥è·Œåœåƒ¹')
       
        l_up = float(limit_up) if limit_up and str(limit_up).replace('.','').isdigit() else None
        l_down = float(limit_down) if limit_down and str(limit_down).replace('.','').isdigit() else None
       
        if l_up is not None and abs(price - l_up) < 0.01:
            status = "ğŸ”´ æ¼²åœ"
        elif l_down is not None and abs(price - l_down) < 0.01:
            status = "ğŸŸ¢ è·Œåœ"
        else:
            points = points_map.get(code, [])
            hit = False
            if isinstance(points, list):
                for p in points:
                    if abs(p['val'] - price) < 0.01:
                        hit = True; break
           
            if not hit:
                note_text = str(row.get('æˆ°ç•¥å‚™è¨»', ''))
                found_prices = re.findall(r'\d+\.?\d*', note_text)
                for fp in found_prices:
                    try:
                        if abs(float(fp) - price) < 0.01:
                            hit = True; break
                    except: pass
           
            if hit: status = "ğŸŸ¡ å‘½ä¸­"
           
        return status
    except: return status

def fetch_stock_data_raw(code, name_hint="", extra_data=None):
    # ï¼ˆæ­¤å‡½æ•¸å…§å®¹å®Œå…¨ä¿æŒåŸæ¨£ï¼Œç¯‡å¹…éé•·æ•…çœç•¥ï¼Œè¤‡è£½ä½ åŸæœ¬çš„å®Œæ•´ç‰ˆæœ¬å³å¯ï¼‰
    # ...ï¼ˆè«‹ä¿ç•™ä½ åŸæœ¬å®Œæ•´çš„ fetch_stock_data_raw å‡½æ•¸ï¼‰
    # æœ€å¾Œ return çš„ dict è«‹ç¢ºä¿åŒ…å« "_auto_note" æ¬„ä½
    pass  # â† è«‹æ›¿æ›æˆä½ åŸæœ¬çš„å®Œæ•´ç¨‹å¼ç¢¼

# ==========================================
# ä¸»ä»‹é¢ (Tabs)
# ==========================================
tab1, tab2 = st.tabs(["âš¡ ç•¶æ²–æˆ°ç•¥å®¤ âš¡", "ğŸ’° ç•¶æ²–æç›Šå®¤ ğŸ’°"])

with tab1:
    col_search, col_file = st.columns([2, 1])
    with col_search:
        code_map, name_map = load_local_stock_names()
        stock_options = [f"{code} {name}" for code, name in sorted(code_map.items())]
       
        src_tab1, src_tab2 = st.tabs(["ğŸ“‚ æœ¬æ©Ÿ", "â˜ï¸ é›²ç«¯"])
        with src_tab1:
            uploaded_file = st.file_uploader("ä¸Šå‚³æª”æ¡ˆ (CSV/XLS/HTML)", type=['xlsx', 'csv', 'html', 'xls'], label_visibility="collapsed")
            selected_sheet = 0
            if uploaded_file:
                try:
                    if not uploaded_file.name.endswith('.csv'):
                        xl_file = pd.ExcelFile(uploaded_file)
                        sheet_options = xl_file.sheet_names
                        default_idx = 0
                        if "é€±è½‰ç‡" in sheet_options: default_idx = sheet_options.index("é€±è½‰ç‡")
                        selected_sheet = st.selectbox("é¸æ“‡å·¥ä½œè¡¨", sheet_options, index=default_idx)
                except: pass
        with src_tab2:
            def on_history_change():
                st.session_state.cloud_url_input = st.session_state.history_selected
            history_opts = st.session_state.url_history if st.session_state.url_history else ["(ç„¡ç´€éŒ„)"]
           
            c_sel, c_del = st.columns([8, 1], gap="small")
           
            with c_sel:
                selected = st.selectbox(
                    "ğŸ“œ æ­·å²ç´€éŒ„ (é¸å–è‡ªå‹•å¡«å…¥)",
                    options=history_opts,
                    key="history_selected",
                    index=None,
                    placeholder="è«‹é¸æ“‡...",
                    on_change=on_history_change,
                    label_visibility="collapsed"
                )
           
            with c_del:
                if st.button("ğŸ—‘ï¸", help="åˆªé™¤é¸å–çš„æ­·å²ç´€éŒ„"):
                    if st.session_state.history_selected and st.session_state.history_selected in st.session_state.url_history:
                        st.session_state.url_history.remove(st.session_state.history_selected)
                        save_url_history(st.session_state.url_history)
                        st.toast("å·²åˆªé™¤ã€‚", icon="ğŸ—‘ï¸")
                        st.rerun()
            st.text_input(
                "è¼¸å…¥é€£çµ (CSV/Excel/Google Sheet)",
                key="cloud_url_input",
                placeholder="https://..."
            )
       
        def update_search_cache():
            save_search_cache(st.session_state.search_multiselect)
        search_selection = st.multiselect(
            "ğŸ” å¿«é€ŸæŸ¥è©¢ (ä¸­æ–‡/ä»£è™Ÿ)",
            options=stock_options,
            key="search_multiselect",
            on_change=update_search_cache,
            placeholder="è¼¸å…¥ 2330 æˆ– å°ç©é›»..."
        )

    if st.button("ğŸš€ åŸ·è¡Œåˆ†æ"):
        # ï¼ˆæ­¤å€å¡Šä¿æŒåŸæ¨£ï¼Œè² è²¬è®€å–æª”æ¡ˆã€æŠ“å–è³‡æ–™ã€å»ºç«‹ stock_dataï¼‰
        # ...ï¼ˆè«‹ä¿ç•™ä½ åŸæœ¬å®Œæ•´çš„ã€ŒåŸ·è¡Œåˆ†æã€ç¨‹å¼ç¢¼ï¼‰
        pass  # â† è«‹æ›¿æ›æˆåŸæœ¬çš„å®Œæ•´ç¨‹å¼

    if not st.session_state.stock_data.empty:
        limit = st.session_state.limit_rows
        df_all = st.session_state.stock_data.copy()
       
        if '_source' not in df_all.columns:
            df_all['_source'] = 'upload'
        df_all = df_all.rename(columns={"æ¼²åœåƒ¹": "ç•¶æ—¥æ¼²åœåƒ¹", "è·Œåœåƒ¹": "ç•¶æ—¥è·Œåœåƒ¹", "ç²åˆ©ç›®æ¨™": "+3%", "é˜²å®ˆåœæ": "-3%"})
        df_all['ä»£è™Ÿ'] = df_all['ä»£è™Ÿ'].astype(str)
        df_all = df_all[~df_all['ä»£è™Ÿ'].isin(st.session_state.ignored_stocks)]
       
        if hide_non_stock:
             mask_etf = df_all['ä»£è™Ÿ'].str.startswith('00')
             mask_warrant = (df_all['ä»£è™Ÿ'].str.len() > 4) & df_all['ä»£è™Ÿ'].str.isdigit()
             df_all = df_all[~(mask_etf | mask_warrant)]
       
        if '_source_rank' in df_all.columns:
            df_all = df_all.sort_values(by=['_source_rank', '_order'])
       
        df_display = df_all.reset_index(drop=True)
        note_width_px = calculate_note_width(df_display['æˆ°ç•¥å‚™è¨»'], current_font_size)
        df_display["ç§»é™¤"] = False
       
        points_map = {}
        if '_points' in df_display.columns:
            points_map = df_display.set_index('ä»£è™Ÿ')['_points'].to_dict()
       
        auto_notes_dict = {}
        if '_auto_note' in df_display.columns:
            auto_notes_dict = df_display.set_index('ä»£è™Ÿ')['_auto_note'].to_dict()

        input_cols = ["ç§»é™¤", "ä»£è™Ÿ", "åç¨±", "æˆ°ç•¥å‚™è¨»", "è‡ªè¨‚åƒ¹(å¯ä¿®)", "ç‹€æ…‹", "ç•¶æ—¥æ¼²åœåƒ¹", "ç•¶æ—¥è·Œåœåƒ¹", "+3%", "-3%", "æ”¶ç›¤åƒ¹", "æ¼²è·Œå¹…", "æœŸè²¨"]
        for col in input_cols:
            if col not in df_display.columns: df_display[col] = None

        cols_to_fmt = ["ç•¶æ—¥æ¼²åœåƒ¹", "ç•¶æ—¥è·Œåœåƒ¹", "+3%", "-3%", "è‡ªè¨‚åƒ¹(å¯ä¿®)"]
        for c in cols_to_fmt:
            if c in df_display.columns: df_display[c] = df_display[c].apply(fmt_price)

        if "æ”¶ç›¤åƒ¹" in df_display.columns and "æ¼²è·Œå¹…" in df_display.columns:
            for i in range(len(df_display)):
                try:
                    p = float(df_display.at[i, "æ”¶ç›¤åƒ¹"])
                    chg = float(df_display.at[i, "æ¼²è·Œå¹…"])
                   
                    color_icon = "âšª"
                    if chg > 0: color_icon = "ğŸ”´"
                    elif chg < 0: color_icon = "ğŸŸ¢"
                   
                    df_display.at[i, "æ”¶ç›¤åƒ¹"] = f"{color_icon} {fmt_price(p)}"
                    chg_str = f"{chg:+.2f}%"
                    df_display.at[i, "æ¼²è·Œå¹…"] = f"{color_icon} {chg_str}"
                except:
                    df_display.at[i, "æ”¶ç›¤åƒ¹"] = fmt_price(df_display.at[i, "æ”¶ç›¤åƒ¹"])
                    df_display.at[i, "æ¼²è·Œå¹…"] = f"{float(df_display.at[i, 'æ¼²è·Œå¹…']):.2f}%"

        df_display = df_display.reset_index(drop=True)
        for col in input_cols:
             if col != "ç§»é™¤": df_display[col] = df_display[col].astype(str)

        edited_df = st.data_editor(
            df_display[input_cols],
            column_config={
                "ç§»é™¤": st.column_config.CheckboxColumn("åˆªé™¤", width=40, help="å‹¾é¸å¾Œåˆªé™¤ä¸¦è‡ªå‹•éè£œ"),
                "ä»£è™Ÿ": st.column_config.TextColumn(disabled=True, width=50),
                "åç¨±": st.column_config.TextColumn(disabled=True, width="small"),
                "æ”¶ç›¤åƒ¹": st.column_config.TextColumn(width="small", disabled=True),
                "æ¼²è·Œå¹…": st.column_config.TextColumn(disabled=True, width="small"),
                "æœŸè²¨": st.column_config.TextColumn(disabled=True, width=40),
                "è‡ªè¨‚åƒ¹(å¯ä¿®)": st.column_config.TextColumn("è‡ªè¨‚åƒ¹ âœï¸", width=60),
                "ç•¶æ—¥æ¼²åœåƒ¹": st.column_config.TextColumn(width="small", disabled=True),
                "ç•¶æ—¥è·Œåœåƒ¹": st.column_config.TextColumn(width="small", disabled=True),
                "+3%": st.column_config.TextColumn(width="small", disabled=True),
                "-3%": st.column_config.TextColumn(width="small", disabled=True),
                "ç‹€æ…‹": st.column_config.TextColumn(width=60, disabled=True),
                "æˆ°ç•¥å‚™è¨»": st.column_config.TextColumn("æˆ°ç•¥å‚™è¨» âœï¸", width=note_width_px, disabled=False),
            },
            hide_index=True,
            use_container_width=False,
            num_rows="fixed",
            key="main_editor"
        )

        # === é—œéµä¿®æ­£ï¼šéœé»˜æ›´æ–°è³‡æ–™ï¼Œä¸è§¸ç™¼ rerun ===
        if not edited_df.empty:
            update_map = edited_df.set_index('ä»£è™Ÿ')[['è‡ªè¨‚åƒ¹(å¯ä¿®)', 'æˆ°ç•¥å‚™è¨»']].to_dict('index')
            
            for i, row in st.session_state.stock_data.iterrows():
                code = str(row['ä»£è™Ÿ'])
                if code in update_map:
                    new_price = update_map[code]['è‡ªè¨‚åƒ¹(å¯ä¿®)']
                    new_note = update_map[code]['æˆ°ç•¥å‚™è¨»']
                    
                    old_price = str(st.session_state.stock_data.at[i, 'è‡ªè¨‚åƒ¹(å¯ä¿®)'] or "")
                    old_note = str(st.session_state.stock_data.at[i, 'æˆ°ç•¥å‚™è¨»'] or "")
                    
                    if old_price != str(new_price):
                        st.session_state.stock_data.at[i, 'è‡ªè¨‚åƒ¹(å¯ä¿®)'] = new_price
                    
                    if old_note != str(new_note):
                        base_auto = auto_notes_dict.get(code, "")
                        pure_manual = new_note
                        if base_auto:
                            if new_note.startswith(base_auto):
                                pure_manual = new_note[len(base_auto):].strip()
                            elif new_note.startswith(base_auto + " "):
                                pure_manual = new_note[len(base_auto)+1:].strip()
                        
                        st.session_state.stock_data.at[i, 'æˆ°ç•¥å‚™è¨»'] = new_note
                        st.session_state.saved_notes[code] = pure_manual

            # è™•ç†ç§»é™¤
            to_remove = edited_df[edited_df["ç§»é™¤"] == True]
            if not to_remove.empty:
                remove_codes = to_remove["ä»£è™Ÿ"].unique()
                for c in remove_codes:
                    st.session_state.ignored_stocks.add(str(c))
               
                st.session_state.stock_data = st.session_state.stock_data[
                    ~st.session_state.stock_data["ä»£è™Ÿ"].isin(remove_codes)
                ]
                save_data_cache(st.session_state.stock_data, st.session_state.ignored_stocks, st.session_state.all_candidates)
                st.rerun()

        # è‡ªå‹•éè£œé‚è¼¯ï¼ˆä¿æŒåŸæ¨£ï¼‰
        # ...ï¼ˆä½ åŸæœ¬çš„éè£œç¨‹å¼ç¢¼ï¼‰

        st.markdown("---")
        
        col_btn, col_info = st.columns([2, 8])
        with col_btn:
            btn_update = st.button("âš¡ åŸ·è¡Œæ›´æ–° (è¨ˆç®—ç‹€æ…‹)", use_container_width=True, type="primary")
        
        with col_info:
            st.info("ğŸ’¡ ä¿®æ”¹ã€Œè‡ªè¨‚åƒ¹ã€æˆ–ã€Œæˆ°ç•¥å‚™è¨»ã€å¾Œï¼Œè«‹é»æ“Š **ã€ŒåŸ·è¡Œæ›´æ–°ã€** æŒ‰éˆ•ï¼Œæ‰æœƒæ›´æ–°ã€Œç‹€æ…‹ã€æ¬„ä½ï¼ˆé¡¯ç¤ºæ¼²åœ/è·Œåœ/å‘½ä¸­ï¼‰ã€‚")

        if btn_update:
            with st.spinner("æ­£åœ¨é‡æ–°è¨ˆç®—æ‰€æœ‰ç‹€æ…‹..."):
                for i, row in st.session_state.stock_data.iterrows():
                    new_status = recalculate_row(row, points_map)
                    st.session_state.stock_data.at[i, 'ç‹€æ…‹'] = new_status
                save_data_cache(st.session_state.stock_data, st.session_state.ignored_stocks, st.session_state.all_candidates)
                st.success("âœ… æ‰€æœ‰ç‹€æ…‹å·²æ›´æ–°å®Œç•¢ï¼")
                st.rerun()

# tab2 ç•¶æ²–æç›Šå®¤ï¼ˆä¿æŒåŸæ¨£ï¼‰
with tab2:
    # ï¼ˆä½ åŸæœ¬çš„æç›Šè¨ˆç®—ç¨‹å¼ç¢¼ï¼Œç„¡éœ€æ”¹å‹•ï¼‰
    pass

**æ³¨æ„ï¼š**
- è«‹å‹™å¿…å°‡ `fetch_stock_data_raw` å‡½æ•¸å®Œæ•´è¤‡è£½å›ä¾†ï¼ˆæˆ‘ä¸Šé¢ç”¨ pass ä»£æ›¿ï¼‰
- å…¶é¤˜ã€ŒåŸ·è¡Œåˆ†æã€æŒ‰éˆ•å…§çš„è³‡æ–™æŠ“å–é‚è¼¯ä¹Ÿè«‹ä¿ç•™åŸæœ¬å®Œæ•´ç¨‹å¼

é€™æ¨£ä¿®æ”¹å¾Œï¼Œä½ å°±å¯ä»¥**å®Œå…¨é †æš¢åœ°é€£çºŒè¼¸å…¥è‡ªè¨‚åƒ¹**ï¼Œä¸æœƒå†è¢«ä¸­æ–·ï¼Œåªæœ‰åœ¨éœ€è¦æ™‚æŒ‰ã€ŒåŸ·è¡Œæ›´æ–°ã€æ‰æœƒåˆ·æ–°ç‹€æ…‹ï¼Œé«”é©—å¤§å¹…æå‡ï¼

å¦‚éœ€é€²ä¸€æ­¥èª¿æ•´æˆ–åŠ å›æŸäº›åŠŸèƒ½ï¼Œéš¨æ™‚å‘Šè¨´æˆ‘ï¼
